{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627b164c-8253-40c6-b1e4-9cbea01230ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5004d",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273b8d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_folder = \"EMG_data_for_gestures-master\"\n",
    "cleaned_data_by_subject = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a912d253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and cleaned data for 36 subjects.\n"
     ]
    }
   ],
   "source": [
    "# Loop through each subject's folder\n",
    "for subject_folder in sorted(os.listdir(master_folder)):\n",
    "    subject_path = os.path.join(master_folder, subject_folder)\n",
    "\n",
    "    if os.path.isdir(subject_path):  # Check if it's a directory\n",
    "        subject_number = int(subject_folder)  # Convert subject folder name to an integer\n",
    "        \n",
    "        trials = []\n",
    "        \n",
    "        for file_name in sorted(os.listdir(subject_path)):\n",
    "            if file_name.endswith('.txt'):\n",
    "                file_path = os.path.join(subject_path, file_name)\n",
    "                \n",
    "                # Load the .txt file with proper handling for mixed types and whitespace delimiter\n",
    "                df = pd.read_csv(file_path, sep='\\s+', dtype=str)  # Load as strings to avoid dtype issues\n",
    "\n",
    "                # Drop 'time' column\n",
    "                df.drop('time', inplace=True, axis=1)\n",
    "                \n",
    "                # Drop rows where 'class' column has NaNs or non-numeric values\n",
    "                df = df[df[\"class\"].notna() & df[\"class\"].str.isnumeric()]\n",
    "                \n",
    "                # Convert 'class' column to integer\n",
    "                df[\"class\"] = df[\"class\"].astype(int)\n",
    "                \n",
    "                # Keep only relevant classes (1 to 6) and drop others\n",
    "                df = df[df[\"class\"].isin([1, 2, 3, 4, 5, 6])]\n",
    "                \n",
    "                # Append the cleaned trial data to the list\n",
    "                trials.append(df)\n",
    "        \n",
    "        # Concatenate trials for the current subject\n",
    "        subject_data = pd.concat(trials, axis=0).reset_index(drop=True)\n",
    "        \n",
    "        # Store the cleaned data for the subject\n",
    "        cleaned_data_by_subject[subject_number] = subject_data\n",
    "\n",
    "print(f\"Loaded and cleaned data for {len(cleaned_data_by_subject)} subjects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d1a40d",
   "metadata": {},
   "source": [
    "# Segment Data by Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a481636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented data for 36 subjects.\n"
     ]
    }
   ],
   "source": [
    "segmented_data_by_subject = {}\n",
    "\n",
    "# Loop through each subject's cleaned data\n",
    "for subject_number, subject_data in cleaned_data_by_subject.items():\n",
    "    segmented_trials = []  # Store segmented data for all trials of this subject\n",
    "\n",
    "    # Sort trials by 'trial' column if applicable\n",
    "    if 'trial' in subject_data.columns:\n",
    "        trials = subject_data.groupby('trial')\n",
    "    else:\n",
    "        trials = [(None, subject_data)]  # Single trial case\n",
    "\n",
    "    # Process each trial separately\n",
    "    for trial_id, trial_data in trials:\n",
    "        trial_segments = []  # Store all segments for this trial\n",
    "\n",
    "        # Identify gesture segments by detecting label changes\n",
    "        current_label = trial_data.iloc[0]['class']  # Start with the first label\n",
    "        start_index = 0  # Index for the beginning of the segment\n",
    "\n",
    "        for i in range(1, len(trial_data)):\n",
    "            if trial_data.iloc[i]['class'] != current_label:\n",
    "                # Extract the segment for the current label\n",
    "                segment = trial_data.iloc[start_index:i]\n",
    "                trial_segments.append(segment)\n",
    "\n",
    "                # Update the current label and start index\n",
    "                current_label = trial_data.iloc[i]['class']\n",
    "                start_index = i\n",
    "\n",
    "        # Capture the last segment\n",
    "        segment = trial_data.iloc[start_index:]\n",
    "        trial_segments.append(segment)\n",
    "\n",
    "        # Add the segmented data for this trial\n",
    "        segmented_trials.extend(trial_segments)\n",
    "\n",
    "    # Store segmented data for the subject\n",
    "    segmented_data_by_subject[subject_number] = segmented_trials\n",
    "\n",
    "print(f\"Segmented data for {len(segmented_data_by_subject)} subjects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a67bf8",
   "metadata": {},
   "source": [
    "# Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f30e4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b99b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sliding_windows(segmented_data, window_size, stride):\n",
    "    \"\"\"\n",
    "    Extracts sliding windows from segmented data.\n",
    "\n",
    "    Args:\n",
    "        segmented_data (dict): Segmented data by subject.\n",
    "        window_size (int): Number of samples in each window.\n",
    "        stride (int): Step size between consecutive windows.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples where each tuple is (window_data, window_label).\n",
    "    \"\"\"\n",
    "    sliding_windows = []\n",
    "\n",
    "    for subject, trials in segmented_data.items():\n",
    "        # print(f\"Processing Subject {subject}...\")\n",
    "        \n",
    "        for segment in trials:\n",
    "            segment_label = segment['class'].iloc[0]  # The class label for the entire segment\n",
    "            segment_data = segment.drop(columns=['class']).values  # Drop the label column\n",
    "            \n",
    "            # Generate windows from this segment\n",
    "            for start_idx in range(0, len(segment_data) - window_size + 1, stride):\n",
    "                window = segment_data[start_idx:start_idx + window_size]\n",
    "                sliding_windows.append((window, segment_label))\n",
    "    \n",
    "    print(f\"Extracted {len(sliding_windows)} windows.\")\n",
    "    return sliding_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "477312dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 11105 windows.\n",
      "Total sliding windows: 11105\n",
      "Window shape: (500, 8), Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Parameters for sliding windows\n",
    "window_size = 500  # e.g., 100 samples per window\n",
    "stride = 100        # e.g., 50-sample step size\n",
    "\n",
    "# Extract sliding windows from segmented data\n",
    "sliding_windows = extract_sliding_windows(segmented_data_by_subject, window_size, stride)\n",
    "\n",
    "# Inspect the number of windows\n",
    "print(f\"Total sliding windows: {len(sliding_windows)}\")\n",
    "\n",
    "# Example: Shape of one window and its label\n",
    "example_window, example_label = sliding_windows[0]\n",
    "print(f\"Window shape: {example_window.shape}, Label: {example_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data and labels from sliding windows\n",
    "X = np.array([window for window, _ in sliding_windows])  # Shape: (num_windows, window_size, num_channels)\n",
    "y = np.array([label for _, label in sliding_windows])   # Shape: (num_windows,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ba2e9",
   "metadata": {},
   "source": [
    "# Feature Extraction with TSFEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b942377",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tsfel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tsfel\n",
    "\n",
    "# Initialize an empty list to store the extracted features\n",
    "X_features = []\n",
    "\n",
    "cfg = tsfel.get_features_by_domain()\n",
    "\n",
    "for domain in cfg.keys():\n",
    "    for feature in list(cfg[domain].keys()):\n",
    "        if feature not in [\n",
    "            \"Mean\",\n",
    "            \"Standard deviation\",\n",
    "            \"Variance\",\n",
    "            \"Waveform Length\",\n",
    "            \"Root Mean Square\",\n",
    "            \"Zero Crossing\",\n",
    "            \"Slope Sign Changes\",\n",
    "            \"Integrated EMG\",\n",
    "            \"Skewness\",\n",
    "            \"Kurtosis\",\n",
    "            \"Spectral Power\",\n",
    "            \"Mean Frequency\",\n",
    "            \"Median Frequency\",\n",
    "        ]:\n",
    "            del cfg[domain][feature]\n",
    "\n",
    "# Iterate through each sliding window\n",
    "for window in X:\n",
    "    # For each channel in the sliding window, extract features\n",
    "    features_per_channel = []\n",
    "    for channel in range(window.shape[1]):  # Assuming (window_size, num_channels)\n",
    "        channel_data = window[:, channel]  # Extract one channel's data\n",
    "        # Convert to DataFrame (required by TSFEL)\n",
    "        channel_df = pd.DataFrame(channel_data, columns=[f'channel_{channel}'])\n",
    "        # Extract features for the channel\n",
    "        channel_features = tsfel.time_series_features_extractor(cfg, channel_df, verbose=0)\n",
    "        features_per_channel.append(channel_features.values.flatten())  # Flatten the extracted features\n",
    "\n",
    "    # Concatenate features from all channels for this window\n",
    "    window_features = np.concatenate(features_per_channel)\n",
    "    X_features.append(window_features)\n",
    "\n",
    "# Convert the list of features to a NumPy array\n",
    "X_features = np.array(X_features)  # Shape: (num_windows, num_features_per_window)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c70a06a5",
   "metadata": {},
   "source": [
    "# Prepare data for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4788b6c0-7646-44af-8f6c-11326bec622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (7773, 40), Validation set: (1666, 40), Test set: (1666, 40)\n",
      "Class labels have been zero-indexed.\n",
      "Data standardized.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming `X_features` is already created by TSFEL feature extraction\n",
    "# Split into training (70%), validation (15%), and test (15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_features, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# Convert training and testing data to float\n",
    "X_train = X_train.astype(float)\n",
    "X_val = X_val.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# Zero-index the class labels by subtracting 1\n",
    "y_train -= 1\n",
    "y_val -= 1\n",
    "y_test -= 1\n",
    "\n",
    "print(\"Class labels have been zero-indexed.\")\n",
    "\n",
    "# Standardize features across the entire training set (per feature/channel)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data standardized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421d39e",
   "metadata": {},
   "source": [
    "# Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b22d9191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       278\n",
      "           1       0.96      0.97      0.97       268\n",
      "           2       0.90      0.93      0.91       277\n",
      "           3       0.91      0.95      0.93       281\n",
      "           4       0.95      0.93      0.94       280\n",
      "           5       0.95      0.88      0.91       282\n",
      "\n",
      "    accuracy                           0.94      1666\n",
      "   macro avg       0.94      0.94      0.94      1666\n",
      "weighted avg       0.94      0.94      0.94      1666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train an SVM model\n",
    "svm = SVC(kernel='rbf')  # You can adjust the kernel as needed\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cd91477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9417767106842737\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and get the accuracy\n",
    "test_accuracy = svm.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c48a1803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (Hinge Loss): 0.1252099935865576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hinge_loss\n",
    "\n",
    "# Predict decision function values for test data\n",
    "y_test_pred = svm.decision_function(X_test)\n",
    "\n",
    "# Calculate hinge loss on the test set\n",
    "test_loss = hinge_loss(y_test, y_test_pred)\n",
    "print(f\"Test Loss (Hinge Loss): {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7bf7730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9339735894357744\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and get the accuracy\n",
    "val_accuracy = svm.score(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfa92f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Hinge Loss): 0.14549018187655222\n"
     ]
    }
   ],
   "source": [
    "# Predict decision function values for test data\n",
    "y_val_pred = svm.decision_function(X_val)\n",
    "\n",
    "# Calculate hinge loss on the validation set\n",
    "val_loss = hinge_loss(y_val, y_val_pred)\n",
    "print(f\"Validation Loss (Hinge Loss): {val_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
